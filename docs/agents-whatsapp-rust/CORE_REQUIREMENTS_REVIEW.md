# Core Requirements Review
## Principal Rust Engineer Assessment

> **Review Date**: January 2025  
> **System**: agents-whatsapp-rust  
> **Reviewer**: Principal Rust Engineer  
> **Status**: üü° **PARTIALLY COMPLETE - CRITICAL GAPS IDENTIFIED**

---

## Executive Summary

This document reviews the implementation status of **core messaging requirements** against the specified functionality. The assessment covers:

1. ‚úÖ **1:1 Text Messages** - Fully implemented
2. ‚ö†Ô∏è **Group Chats (100 participants)** - Models exist, validation missing
3. üî¥ **30-Day Message Queuing** - Not implemented
4. ‚ö†Ô∏è **Media Attachments** - Models exist, service missing
5. ‚úÖ **Message Status Tracking** - Fully implemented
6. ‚úÖ **Online/Offline Status** - Fully implemented

**Overall Assessment**: üü° **PARTIALLY READY**
- ‚úÖ Core messaging infrastructure is solid
- ‚úÖ Real-time delivery works correctly
- ‚ö†Ô∏è Group chat validation needs implementation
- üî¥ **CRITICAL**: 30-day message retention not implemented
- ‚ö†Ô∏è Media service needs to be built

---

## Requirement 1: 1:1 Text Messages ‚úÖ

### Status: **FULLY IMPLEMENTED**

### Evidence

**Models Support** (`shared/src/models.rs`):
```rust
pub struct MessagePayload {
    pub conversation_id: String,
    pub receiver_id: String,
    pub content: String, // E2EE encrypted
    pub message_type: MessageType,
    // ...
}

pub enum ConversationType {
    #[serde(rename = "1:1")]
    OneToOne,
    Group,
}
```

**WebSocket Handler** (`messaging-service/src/handlers.rs`):
- ‚úÖ Handles `WebSocketMessage::Message` with text content
- ‚úÖ Validates idempotency keys
- ‚úÖ Generates sequence numbers per conversation
- ‚úÖ Publishes to Knative Broker for async processing
- ‚úÖ Sends immediate ACK to client

**Message Storage** (`message-storage-service/src/handlers.rs`):
- ‚úÖ Stores messages in MongoDB
- ‚úÖ Routes to online users via Redis Pub/Sub
- ‚úÖ Queues for offline users in Redis inbox

### Implementation Quality

**Strengths**:
- ‚úÖ Proper idempotency handling prevents duplicates
- ‚úÖ Sequence numbers ensure message ordering
- ‚úÖ Async processing via Knative Broker (non-blocking)
- ‚úÖ Immediate ACK to client (low latency)
- ‚úÖ Offline message queuing in Redis inbox

**Gaps**: None identified for 1:1 messaging

### Recommendation

‚úÖ **APPROVED** - No changes needed for 1:1 text messaging.

---

## Requirement 2: Group Chats (Up to 100 Participants) ‚ö†Ô∏è

### Status: **PARTIALLY IMPLEMENTED**

### Evidence

**Models Support** (`shared/src/models.rs`):
```rust
pub struct Conversation {
    pub conversation_type: ConversationType,
    pub participants: Vec<String>,  // ‚úÖ Supports multiple participants
    // ...
}

pub enum ConversationType {
    OneToOne,
    Group,  // ‚úÖ Group type exists
}
```

**Missing Implementation**:
- ‚ùå No validation to enforce 100-participant limit
- ‚ùå No group creation endpoint
- ‚ùå No participant management (add/remove)
- ‚ùå No group-specific message routing logic

### Current Behavior

The system **can** store group conversations in MongoDB, but:
1. No validation prevents >100 participants
2. No API endpoints to create/manage groups
3. Message routing assumes 1:1 (single `receiver_id`)

### Critical Gaps

#### Gap 1: Participant Limit Validation

**Location**: `user-service/src/handlers.rs` (group creation endpoint - **MISSING**)

**Required Implementation**:
```rust
pub async fn create_group_conversation(
    State(state): State<Arc<AppState>>,
    Json(payload): Json<CreateGroupPayload>,
) -> Result<Json<Conversation>, AppError> {
    // CRITICAL: Enforce 100-participant limit
    if payload.participants.len() > 100 {
        return Err(AppError::Validation(
            "Group chat cannot exceed 100 participants".to_string()
        ));
    }
    
    // Validate all participants exist
    for participant_id in &payload.participants {
        if !state.db.collection::<User>("users")
            .find_one(doc! { "_id": participant_id }, None)
            .await?
            .is_some() {
            return Err(AppError::Validation(
                format!("Participant {} not found", participant_id)
            ));
        }
    }
    
    // Create conversation
    let conversation = Conversation {
        conversation_id: Some(generate_id()),
        user_id: payload.creator_id,
        agent_id: String::new(), // Groups don't have agents
        conversation_type: ConversationType::Group,
        participants: payload.participants,
        last_sequence_number: 0,
        last_message_at: None,
        created_at: Utc::now(),
    };
    
    // Store in MongoDB
    state.db.collection("conversations")
        .insert_one(bson::to_document(&conversation)?, None)
        .await?;
    
    Ok(Json(conversation))
}
```

#### Gap 2: Group Message Routing

**Location**: `message-storage-service/src/handlers.rs` (line 96-138)

**Current Code**:
```rust
// ‚ùå Only handles single receiver_id
let receiver_id = data.get("receiver_id")?;
```

**Required Implementation**:
```rust
// Check if this is a group conversation
let conversation = state.db.collection::<Conversation>("conversations")
    .find_one(doc! { "_id": conversation_id }, None)
    .await?;

if let Some(conv) = conversation {
    match conv.conversation_type {
        ConversationType::Group => {
            // Broadcast to all participants (except sender)
            for participant_id in &conv.participants {
                if participant_id != &sender_id {
                    // Check if participant is online
                    let is_online = check_user_online(participant_id, &state.redis).await?;
                    
                    if is_online {
                        // Publish to participant's channel
                        publish_to_user(participant_id, &message, &state.redis).await?;
                    } else {
                        // Add to participant's inbox
                        add_to_inbox(participant_id, &message_id, &state.redis).await?;
                    }
                }
            }
        }
        ConversationType::OneToOne => {
            // Existing 1:1 logic
        }
    }
}
```

#### Gap 3: Participant Management

**Missing Endpoints**:
- `POST /api/v1/conversations/{id}/participants` - Add participant
- `DELETE /api/v1/conversations/{id}/participants/{user_id}` - Remove participant
- `GET /api/v1/conversations/{id}/participants` - List participants

**Required Validation**:
```rust
// When adding participant
if conv.participants.len() >= 100 {
    return Err(AppError::Validation(
        "Group chat has reached maximum capacity (100 participants)".to_string()
    ));
}
```

### Recommendation

‚ö†Ô∏è **REQUIRES IMPLEMENTATION** - Group chat models exist but functionality is incomplete.

**Priority**: **HIGH** (Core requirement)

**Action Items**:
1. ‚úÖ Add participant limit validation (100 max)
2. ‚úÖ Implement group conversation creation endpoint
3. ‚úÖ Implement group message routing (broadcast to all participants)
4. ‚úÖ Add participant management endpoints (add/remove)
5. ‚úÖ Add group conversation queries (list groups, get group details)

**Estimated Effort**: 2-3 days

---

## Requirement 3: 30-Day Message Queuing üî¥

### Status: **NOT IMPLEMENTED**

### Evidence

**Current Implementation** (`message-storage-service/src/handlers.rs`):
```rust
if !is_online {
    // User is offline, add to inbox
    let inbox_key = format!("inbox:{}", receiver_id);
    redis::cmd("LPUSH")
        .arg(&inbox_key)
        .arg(message_id)
        .query_async(&mut conn)
        .await?;
    
    info!("Added message to inbox for offline user: {}", receiver_id);
}
```

**Problems**:
- ‚ùå No TTL on Redis inbox keys (messages never expire)
- ‚ùå No expiration logic for old messages
- ‚ùå No cleanup job to remove messages >30 days old
- ‚ùå MongoDB messages have no TTL index for 30-day retention

### Critical Gaps

#### Gap 1: Redis Inbox TTL

**Location**: `message-storage-service/src/handlers.rs` (line 105-110)

**Current Code**:
```rust
redis::cmd("LPUSH")
    .arg(&inbox_key)
    .arg(message_id)
    .query_async(&mut conn)
    .await?;
// ‚ùå No TTL set - messages never expire
```

**Required Fix**:
```rust
// Add message to inbox
redis::cmd("LPUSH")
    .arg(&inbox_key)
    .arg(message_id)
    .query_async(&mut conn)
    .await?;

// CRITICAL: Set TTL to 30 days (2,592,000 seconds)
redis::cmd("EXPIRE")
    .arg(&inbox_key)
    .arg(2592000)  // 30 days in seconds
    .query_async(&mut conn)
    .await?;
```

#### Gap 2: MongoDB Message TTL Index

**Location**: Database initialization (missing)

**Required Implementation**:
```rust
// In message-storage-service/src/main.rs or initialization code
pub async fn setup_mongodb_indexes(db: &Database) -> AppResult<()> {
    let collection = db.collection::<Document>("messages");
    
    // Create TTL index on created_at field (30 days)
    let index_model = IndexModel::builder()
        .keys(doc! { "created_at": 1 })
        .options(IndexOptions::builder()
            .expire_after(Duration::seconds(2592000))  // 30 days
            .name("created_at_ttl_idx".to_string())
            .build())
        .build();
    
    collection.create_index(index_model, None).await?;
    
    info!("Created TTL index on messages collection (30 days)");
    Ok(())
}
```

#### Gap 3: Cleanup Job for Old Messages

**Location**: New service or background task (missing)

**Required Implementation**:
```rust
// Background task to clean up expired messages
pub async fn cleanup_expired_messages(state: Arc<AppState>) {
    let mut interval = tokio::time::interval(Duration::from_secs(3600)); // Run every hour
    
    loop {
        interval.tick().await;
        
        let cutoff_date = Utc::now() - Duration::days(30);
        
        // Delete messages older than 30 days
        let collection = state.db.collection::<Document>("messages");
        let filter = doc! {
            "created_at": { "$lt": cutoff_date }
        };
        
        match collection.delete_many(filter, None).await {
            Ok(result) => {
                if result.deleted_count > 0 {
                    info!("Cleaned up {} expired messages", result.deleted_count);
                }
            }
            Err(e) => {
                error!("Failed to cleanup expired messages: {}", e);
            }
        }
        
        // Also cleanup Redis inboxes (they should auto-expire, but clean up stale ones)
        cleanup_stale_inboxes(&state.redis).await;
    }
}
```

#### Gap 4: Message Delivery on Reconnect

**Location**: `messaging-service/src/handlers.rs` (line 207-237)

**Current Implementation**:
```rust
async fn deliver_pending_messages(
    user_id: &str,
    storage: &mut Storage,
    tx: &mpsc::UnboundedSender<axum::extract::ws::Message>,
) -> AppResult<()> {
    // Get pending messages from Redis inbox
    let pending = storage.get_pending_messages(user_id).await?;
    // ...
}
```

**Required Enhancement**:
```rust
async fn deliver_pending_messages(
    user_id: &str,
    storage: &mut Storage,
    tx: &mpsc::UnboundedSender<axum::extract::ws::Message>,
) -> AppResult<()> {
    // Get pending messages from Redis inbox
    let pending = storage.get_pending_messages(user_id).await?;
    
    // CRITICAL: Filter out messages older than 30 days
    let cutoff = Utc::now() - Duration::days(30);
    let valid_messages: Vec<_> = pending
        .into_iter()
        .filter(|msg| msg.created_at >= cutoff)
        .collect();
    
    // Only deliver messages within 30-day window
    for message in valid_messages {
        // ... deliver message
    }
    
    Ok(())
}
```

### Recommendation

üî¥ **CRITICAL GAP** - 30-day message retention is a core requirement and is **NOT IMPLEMENTED**.

**Priority**: **CRITICAL** (Core requirement)

**Action Items**:
1. üî¥ Add TTL to Redis inbox keys (30 days)
2. üî¥ Create MongoDB TTL index on `messages.created_at` (30 days)
3. üî¥ Implement cleanup job for expired messages
4. üî¥ Filter expired messages during delivery on reconnect
5. üî¥ Add monitoring/alerting for message expiration

**Estimated Effort**: 1-2 days

**Impact**: Without this, messages will accumulate indefinitely, causing:
- Storage bloat
- Performance degradation
- Cost overruns
- Non-compliance with requirements

---

## Requirement 4: Media Attachments (Images, Videos, Audio) ‚ö†Ô∏è

### Status: **PARTIALLY IMPLEMENTED**

### Evidence

**Models Support** (`shared/src/models.rs`):
```rust
pub enum MessageType {
    Text,
    Image,   // ‚úÖ Model exists
    Video,   // ‚úÖ Model exists
    Audio,   // ‚úÖ Model exists
    Document,
    Location,
    System,
}

pub struct MessagePayload {
    pub media_url: Option<String>,  // ‚úÖ Field exists
    // ...
}
```

**Missing Implementation**:
- ‚ùå No Media Service implementation
- ‚ùå No file upload endpoints
- ‚ùå No MinIO/S3 integration
- ‚ùå No presigned URL generation
- ‚ùå No media processing (thumbnails, compression)

### Current Behavior

The system **can** store media URLs in messages, but:
1. No way to upload files
2. No way to generate presigned URLs
3. No media processing pipeline
4. No CDN integration

### Critical Gaps

#### Gap 1: Media Service Missing

**Location**: `media-service/` directory (referenced in docs but **NOT IMPLEMENTED**)

**Required Implementation** (from `REQUIREMENTS.md`):
```rust
// media-service/src/handlers.rs
pub async fn generate_presigned_url(
    State(state): State<Arc<AppState>>,
    Json(payload): Json<PresignedUrlRequest>,
) -> Result<Json<PresignedUrlResponse>, AppError> {
    // Generate presigned URL for direct client upload to MinIO
    let url = state.minio_client
        .presigned_put_object(
            &payload.bucket,
            &payload.key,
            Duration::from_secs(3600), // 1 hour expiry
        )
        .await?;
    
    Ok(Json(PresignedUrlResponse {
        upload_url: url,
        file_id: generate_file_id(),
        expires_in: 3600,
    }))
}

pub async fn process_media(
    State(state): State<Arc<AppState>>,
    Json(payload): Json<MediaProcessRequest>,
) -> Result<Json<MediaMetadata>, AppError> {
    // Download from MinIO
    // Generate thumbnails (for images/videos)
    // Compress media
    // Store metadata in MongoDB
    // Return CDN URL
}
```

#### Gap 2: Media Upload Flow

**Required Flow** (from `ARCHITECTURE.md`):
1. Client requests presigned URL from Media Service
2. Client uploads directly to MinIO using presigned URL
3. Client notifies Media Service upload complete
4. Media Service processes file (thumbnails, compression)
5. Media Service stores metadata in MongoDB
6. Media URL returned to client for message attachment

**Current Status**: ‚ùå None of these steps are implemented

### Recommendation

‚ö†Ô∏è **REQUIRES IMPLEMENTATION** - Media models exist but service is missing.

**Priority**: **MEDIUM** (Can be deferred to Phase 4 per requirements)

**Action Items**:
1. ‚ö†Ô∏è Implement Media Service (Rust/Axum)
2. ‚ö†Ô∏è Integrate MinIO client for presigned URLs
3. ‚ö†Ô∏è Implement media processing (thumbnails, compression)
4. ‚ö†Ô∏è Add media metadata storage in MongoDB
5. ‚ö†Ô∏è Integrate CDN for fast delivery

**Estimated Effort**: 3-5 days

**Note**: Per `REQUIREMENTS.md` Phase 4, media support is planned for "Weeks 11-14", so this can be deferred if 1:1 text messaging is the MVP priority.

---

## Requirement 5: Message Status Tracking (Sent, Delivered, Read) ‚úÖ

### Status: **FULLY IMPLEMENTED**

### Evidence

**Models Support** (`shared/src/models.rs`):
```rust
pub enum MessageStatus {
    Sent,      // ‚úÖ Implemented
    Delivered, // ‚úÖ Implemented
    Read,      // ‚úÖ Implemented
}

pub struct StoredMessage {
    pub status: MessageStatus,  // ‚úÖ Status tracked
    // ...
}
```

**Implementation**:

1. **Sent Status** (`messaging-service/src/handlers.rs`):
```rust
let ack = WebSocketMessage::MessageAck {
    client_message_id: client_message_id.unwrap_or_default(),
    payload: MessageAckPayload {
        message_id: message_id.clone(),
        sequence_number,
        status: MessageStatus::Sent,  // ‚úÖ Sent immediately
        timestamp: Utc::now().timestamp_millis(),
    },
};
```

2. **Delivered Status** (`message-storage-service/src/handlers.rs`):
```rust
let ws_message = serde_json::json!({
    "status": "delivered",  // ‚úÖ Delivered when published to Pub/Sub
    // ...
});
```

3. **Read Receipts** (`shared/src/models.rs`):
```rust
pub enum WebSocketMessage {
    ReadReceipt {
        message_ids: Vec<String>,
        timestamp: i64,
    },
    // ...
}
```

**WebSocket Protocol**:
- ‚úÖ `MessageAck` - Sent status (immediate)
- ‚úÖ `DeliveryAck` - Delivered status (when received)
- ‚úÖ `ReadReceipt` - Read status (when user reads)

### Implementation Quality

**Strengths**:
- ‚úÖ Status tracked in MongoDB (`StoredMessage.status`)
- ‚úÖ Real-time status updates via WebSocket
- ‚úÖ Read receipts supported in protocol
- ‚úÖ Status persisted for message history

**Gaps**: None identified

### Recommendation

‚úÖ **APPROVED** - Message status tracking is fully implemented and working correctly.

---

## Requirement 6: Online/Offline Status with "Last Seen" ‚úÖ

### Status: **FULLY IMPLEMENTED**

### Evidence

**Models Support** (`shared/src/models.rs`):
```rust
pub struct User {
    pub last_seen: Option<DateTime<Utc>>,  // ‚úÖ Last seen tracked
    pub status: UserStatus,                // ‚úÖ Online/offline status
}

pub enum UserStatus {
    Online,   // ‚úÖ Implemented
    Offline,  // ‚úÖ Implemented
}

pub struct Presence {
    pub status: UserStatus,
    pub last_seen: i64,  // ‚úÖ Timestamp in milliseconds
}
```

**Implementation**:

1. **Heartbeat Updates** (`messaging-service/src/connection.rs`):
```rust
pub async fn update_heartbeat(&self) -> AppResult<()> {
    if let Some(user_id) = &self.user_id {
        let key = format!("presence:{}", user_id);
        let value = serde_json::json!({
            "status": "online",
            "last_seen": Utc::now().timestamp_millis(),  // ‚úÖ Updated on heartbeat
        });
        
        conn.set_ex::<String, String, ()>(key, value.to_string(), 300).await?;
        // ‚úÖ TTL of 300 seconds (5 minutes) - user goes offline if no heartbeat
    }
    Ok(())
}
```

2. **Heartbeat Handler** (`messaging-service/src/handlers.rs`):
```rust
WebSocketMessage::Heartbeat { timestamp: _ } => {
    connection.update_heartbeat().await?;  // ‚úÖ Updates presence
    
    let ack = WebSocketMessage::HeartbeatAck {
        server_time: Utc::now().timestamp_millis(),
    };
    // ...
}
```

3. **Connection Registry** (`messaging-service/src/connection.rs`):
```rust
pub async fn register(&mut self, user_id: &str) -> AppResult<()> {
    let key = format!("connection:{}", user_id);
    // ‚úÖ Registers user as online when WebSocket connects
    conn.set_ex::<String, String, ()>(key, value.to_string(), 3600).await?;
}
```

4. **Cleanup on Disconnect** (`messaging-service/src/connection.rs`):
```rust
pub async fn cleanup(&self) {
    let key = format!("connection:{}", user_id);
    redis::cmd("DEL").arg(&key).query_async(&mut conn).await;
    // ‚úÖ Removes connection registry on disconnect
}
```

### Implementation Quality

**Strengths**:
- ‚úÖ Presence tracked in Redis (fast lookups)
- ‚úÖ Heartbeat updates `last_seen` every 5 seconds
- ‚úÖ TTL-based offline detection (5 minutes)
- ‚úÖ Connection registry tracks active WebSocket connections
- ‚úÖ Cleanup on disconnect removes presence

**Potential Enhancement**:
- ‚ö†Ô∏è Consider updating MongoDB `User.last_seen` periodically (not just Redis)
- ‚ö†Ô∏è Consider presence service for cross-instance presence queries

### Recommendation

‚úÖ **APPROVED** - Online/offline status and "last seen" are fully implemented.

**Optional Enhancement** (Low Priority):
- Sync `User.last_seen` to MongoDB periodically (for historical queries)
- Dedicated Presence Service for cross-instance presence (already planned per `ARCHITECTURE.md`)

---

## Summary & Action Plan

### Implementation Status

| Requirement | Status | Priority | Effort |
|------------|--------|----------|--------|
| 1:1 Text Messages | ‚úÖ Complete | - | - |
| Group Chats (100) | ‚ö†Ô∏è Partial | HIGH | 2-3 days |
| 30-Day Queuing | üî¥ Missing | **CRITICAL** | 1-2 days |
| Media Attachments | ‚ö†Ô∏è Partial | MEDIUM | 3-5 days |
| Message Status | ‚úÖ Complete | - | - |
| Online/Offline | ‚úÖ Complete | - | - |

### Critical Path

**Must Fix Before Production**:
1. üî¥ **30-Day Message Retention** (1-2 days)
   - Add Redis inbox TTL
   - Create MongoDB TTL index
   - Implement cleanup job
   - Filter expired messages on delivery

2. ‚ö†Ô∏è **Group Chat Validation** (2-3 days)
   - Add 100-participant limit validation
   - Implement group message routing
   - Add participant management endpoints

**Can Defer**:
3. ‚ö†Ô∏è **Media Service** (3-5 days) - Per requirements, this is Phase 4

### Recommendations

1. **Immediate Action**: Implement 30-day message retention (critical gap)
2. **High Priority**: Complete group chat functionality (core requirement)
3. **Medium Priority**: Build media service (Phase 4 per requirements)

### Code Quality Assessment

**Strengths**:
- ‚úÖ Clean Rust code with proper error handling
- ‚úÖ Good separation of concerns (services, models, handlers)
- ‚úÖ Proper async/await usage (Tokio)
- ‚úÖ Idempotency and sequence numbers implemented correctly
- ‚úÖ WebSocket protocol well-designed

**Areas for Improvement**:
- ‚ö†Ô∏è Add integration tests for group chats
- ‚ö†Ô∏è Add monitoring for message expiration
- ‚ö†Ô∏è Document TTL behavior in code comments

---

## Conclusion

The core messaging infrastructure is **solid** and handles 1:1 messaging, status tracking, and presence correctly. However, **two critical gaps** must be addressed:

1. üî¥ **30-day message retention** - Not implemented (critical)
2. ‚ö†Ô∏è **Group chat validation** - Models exist but functionality incomplete (high priority)

**Recommendation**: Fix 30-day retention immediately, then complete group chat functionality before considering production deployment.

---

**Review Completed**: January 2025  
**Next Review**: After critical gaps are addressed
