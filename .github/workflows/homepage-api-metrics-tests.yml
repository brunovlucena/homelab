name: Homepage API Metrics Tests

on:
  push:
    branches: [ main, develop ]
    paths:
      - 'flux/clusters/homelab/infrastructure/homepage/api/**'
      - 'flux/clusters/homelab/infrastructure/homepage/chart/templates/prometheus-rules.yaml'
      - '.github/workflows/homepage-api-metrics-tests.yml'
  pull_request:
    branches: [ main, develop ]
    paths:
      - 'flux/clusters/homelab/infrastructure/homepage/api/**'
      - 'flux/clusters/homelab/infrastructure/homepage/chart/templates/prometheus-rules.yaml'
  workflow_dispatch:

env:
  GO_VERSION: '1.23.0'
  HOMEPAGE_API_PATH: 'flux/clusters/homelab/infrastructure/homepage/api'

jobs:
  # ============================================================================
  # 📊 Metrics Package Tests
  # ============================================================================
  metrics-package-tests:
    name: Metrics Package Tests
    runs-on: ubuntu-latest
    
    steps:
      - name: 📥 Checkout code
        uses: actions/checkout@v4

      - name: 🔧 Setup Go
        uses: actions/setup-go@v5
        with:
          go-version: ${{ env.GO_VERSION }}
          cache-dependency-path: ${{ env.HOMEPAGE_API_PATH }}/go.sum

      - name: 📦 Install dependencies
        working-directory: ${{ env.HOMEPAGE_API_PATH }}
        run: |
          go mod download
          go mod verify

      - name: 🧪 Run metrics package tests
        working-directory: ${{ env.HOMEPAGE_API_PATH }}
        run: |
          echo "### 📊 Metrics Package Tests" >> $GITHUB_STEP_SUMMARY
          go test -v -race -coverprofile=metrics-coverage.out ./metrics/
          
          if [ $? -eq 0 ]; then
            echo "✅ All metrics tests passed" >> $GITHUB_STEP_SUMMARY
          else
            echo "❌ Metrics tests failed" >> $GITHUB_STEP_SUMMARY
            exit 1
          fi

      - name: 📊 Metrics package coverage
        working-directory: ${{ env.HOMEPAGE_API_PATH }}
        run: |
          COVERAGE=$(go tool cover -func=metrics-coverage.out | grep total | awk '{print $3}')
          echo "### Metrics Package Coverage: $COVERAGE" >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          go tool cover -func=metrics-coverage.out >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY

  # ============================================================================
  # 🧪 Handler Instrumentation Tests
  # ============================================================================
  handler-instrumentation-tests:
    name: Handler Metrics Instrumentation Tests
    runs-on: ubuntu-latest
    
    steps:
      - name: 📥 Checkout code
        uses: actions/checkout@v4

      - name: 🔧 Setup Go
        uses: actions/setup-go@v5
        with:
          go-version: ${{ env.GO_VERSION }}
          cache-dependency-path: ${{ env.HOMEPAGE_API_PATH }}/go.sum

      - name: 📦 Install dependencies
        working-directory: ${{ env.HOMEPAGE_API_PATH }}
        run: |
          go mod download
          go mod verify

      - name: 🧪 Run projects metrics tests
        working-directory: ${{ env.HOMEPAGE_API_PATH }}
        run: |
          echo "### 📦 Projects Metrics Tests" >> $GITHUB_STEP_SUMMARY
          go test -v -run TestProjects ./handlers/
          
          if [ $? -eq 0 ]; then
            echo "✅ Projects metrics tests passed" >> $GITHUB_STEP_SUMMARY
          else
            echo "❌ Projects metrics tests failed" >> $GITHUB_STEP_SUMMARY
            exit 1
          fi

      - name: 🧪 Run experience metrics tests
        working-directory: ${{ env.HOMEPAGE_API_PATH }}
        run: |
          echo "### 💼 Experience Metrics Tests" >> $GITHUB_STEP_SUMMARY
          go test -v -run TestExperience ./handlers/ || true
          
          # Check if experience metrics are implemented
          if grep -q "RecordExperienceLoadError\|RecordExperienceLoadSuccess" handlers/*.go; then
            echo "✅ Experience metrics found" >> $GITHUB_STEP_SUMMARY
          else
            echo "⚠️ Experience metrics not yet implemented" >> $GITHUB_STEP_SUMMARY
          fi

      - name: 🧪 Run all handler metrics tests
        working-directory: ${{ env.HOMEPAGE_API_PATH }}
        run: |
          echo "### 🎯 All Handler Metrics Tests" >> $GITHUB_STEP_SUMMARY
          go test -v -race -coverprofile=handlers-coverage.out ./handlers/
          
          COVERAGE=$(go tool cover -func=handlers-coverage.out | grep total | awk '{print $3}')
          echo "Handler Coverage: $COVERAGE" >> $GITHUB_STEP_SUMMARY

  # ============================================================================
  # 📈 Metrics Endpoint Verification
  # ============================================================================
  metrics-endpoint-tests:
    name: Metrics Endpoint Tests
    runs-on: ubuntu-latest
    
    steps:
      - name: 📥 Checkout code
        uses: actions/checkout@v4

      - name: 🔧 Setup Go
        uses: actions/setup-go@v5
        with:
          go-version: ${{ env.GO_VERSION }}
          cache-dependency-path: ${{ env.HOMEPAGE_API_PATH }}/go.sum

      - name: 📦 Install dependencies
        working-directory: ${{ env.HOMEPAGE_API_PATH }}
        run: go mod download

      - name: 🔍 Verify /metrics endpoint exists
        working-directory: ${{ env.HOMEPAGE_API_PATH }}
        run: |
          echo "### 📈 Metrics Endpoint Verification" >> $GITHUB_STEP_SUMMARY
          
          # Check if metrics endpoint is registered in router
          if grep -q "r.GET.*\"/metrics\"" router/router.go; then
            echo "✅ Metrics endpoint found in router" >> $GITHUB_STEP_SUMMARY
          else
            echo "❌ Metrics endpoint not found in router" >> $GITHUB_STEP_SUMMARY
            exit 1
          fi
          
          # Check if promhttp is imported
          if grep -q "prometheus/client_golang/prometheus/promhttp" router/router.go; then
            echo "✅ Prometheus HTTP handler imported" >> $GITHUB_STEP_SUMMARY
          else
            echo "❌ Prometheus HTTP handler not imported" >> $GITHUB_STEP_SUMMARY
            exit 1
          fi

      - name: 🔍 Verify metrics are defined
        working-directory: ${{ env.HOMEPAGE_API_PATH }}
        run: |
          echo "### 📊 Defined Metrics" >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          grep -E "promauto\.New(Counter|Histogram|Gauge)" metrics/metrics.go | head -20 >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY

  # ============================================================================
  # 🚨 Prometheus Alert Rules Validation
  # ============================================================================
  prometheus-alert-validation:
    name: Prometheus Alert Rules Validation
    runs-on: ubuntu-latest
    
    steps:
      - name: 📥 Checkout code
        uses: actions/checkout@v4

      - name: 🔧 Setup promtool
        run: |
          wget https://github.com/prometheus/prometheus/releases/download/v2.54.1/prometheus-2.54.1.linux-amd64.tar.gz
          tar xvfz prometheus-2.54.1.linux-amd64.tar.gz
          sudo mv prometheus-2.54.1.linux-amd64/promtool /usr/local/bin/

      - name: 🔍 Validate alert rules
        run: |
          echo "### 🚨 Alert Rules Validation" >> $GITHUB_STEP_SUMMARY
          
          # Extract alert rules from Kubernetes manifest
          RULES_FILE="flux/clusters/homelab/infrastructure/homepage/chart/templates/prometheus-rules.yaml"
          
          if [ ! -f "$RULES_FILE" ]; then
            echo "❌ Prometheus rules file not found" >> $GITHUB_STEP_SUMMARY
            exit 1
          fi
          
          # Check for projects metrics alerts
          if grep -q "bruno_site_projects_load_errors_total" "$RULES_FILE"; then
            echo "✅ Projects load error alert found" >> $GITHUB_STEP_SUMMARY
          else
            echo "⚠️ Projects load error alert not found" >> $GITHUB_STEP_SUMMARY
          fi
          
          # Check for experience metrics alerts
          if grep -q "bruno_site_experience_load_errors_total" "$RULES_FILE"; then
            echo "✅ Experience load error alert found" >> $GITHUB_STEP_SUMMARY
          else
            echo "⚠️ Experience load error alert not found" >> $GITHUB_STEP_SUMMARY
          fi
          
          # List all bruno_site metrics alerts
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Configured Alerts" >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          grep -E "bruno_site_.*_(load_errors|load_success|load_duration)" "$RULES_FILE" | head -10 >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY

      - name: 🔍 Check alert coverage
        run: |
          echo "### 📋 Alert Coverage" >> $GITHUB_STEP_SUMMARY
          
          RULES_FILE="flux/clusters/homelab/infrastructure/homepage/chart/templates/prometheus-rules.yaml"
          
          # Count alerts
          PROJECTS_ALERTS=$(grep -c "BrunoSiteProjects" "$RULES_FILE" || echo 0)
          EXPERIENCE_ALERTS=$(grep -c "BrunoSiteExperience" "$RULES_FILE" || echo 0)
          DATABASE_ALERTS=$(grep -c "BrunoSiteDatabase" "$RULES_FILE" || echo 0)
          
          echo "| Component | Alerts |" >> $GITHUB_STEP_SUMMARY
          echo "|-----------|--------|" >> $GITHUB_STEP_SUMMARY
          echo "| Projects | $PROJECTS_ALERTS |" >> $GITHUB_STEP_SUMMARY
          echo "| Experience | $EXPERIENCE_ALERTS |" >> $GITHUB_STEP_SUMMARY
          echo "| Database | $DATABASE_ALERTS |" >> $GITHUB_STEP_SUMMARY

  # ============================================================================
  # 🏃 Benchmark Tests
  # ============================================================================
  metrics-benchmark:
    name: Metrics Performance Benchmark
    runs-on: ubuntu-latest
    
    steps:
      - name: 📥 Checkout code
        uses: actions/checkout@v4

      - name: 🔧 Setup Go
        uses: actions/setup-go@v5
        with:
          go-version: ${{ env.GO_VERSION }}
          cache-dependency-path: ${{ env.HOMEPAGE_API_PATH }}/go.sum

      - name: 📦 Install dependencies
        working-directory: ${{ env.HOMEPAGE_API_PATH }}
        run: go mod download

      - name: 🏃 Run benchmark tests
        working-directory: ${{ env.HOMEPAGE_API_PATH }}
        run: |
          echo "### 🏃 Benchmark Results" >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          go test -bench=. -benchmem ./handlers/ 2>&1 | tee benchmark.txt
          cat benchmark.txt >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY

      - name: 📊 Upload benchmark results
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-results
          path: ${{ env.HOMEPAGE_API_PATH }}/benchmark.txt
          retention-days: 30

  # ============================================================================
  # 🔍 Metrics Code Quality
  # ============================================================================
  metrics-code-quality:
    name: Metrics Code Quality
    runs-on: ubuntu-latest
    
    steps:
      - name: 📥 Checkout code
        uses: actions/checkout@v4

      - name: 🔧 Setup Go
        uses: actions/setup-go@v5
        with:
          go-version: ${{ env.GO_VERSION }}
          cache-dependency-path: ${{ env.HOMEPAGE_API_PATH }}/go.sum

      - name: 🔍 Check metrics naming conventions
        working-directory: ${{ env.HOMEPAGE_API_PATH }}
        run: |
          echo "### 📊 Metrics Naming Convention Check" >> $GITHUB_STEP_SUMMARY
          
          # Check if all metrics follow bruno_site_ prefix
          METRICS_WITHOUT_PREFIX=$(grep -E "Name:.*\"[^\"]*\"" metrics/metrics.go | grep -v "bruno_site_" || true)
          
          if [ -z "$METRICS_WITHOUT_PREFIX" ]; then
            echo "✅ All metrics follow bruno_site_ prefix" >> $GITHUB_STEP_SUMMARY
          else
            echo "⚠️ Some metrics don't follow naming convention:" >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
            echo "$METRICS_WITHOUT_PREFIX" >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
          fi

      - name: 🔍 Check for metric helper functions
        working-directory: ${{ env.HOMEPAGE_API_PATH }}
        run: |
          echo "### 🔧 Metric Helper Functions" >> $GITHUB_STEP_SUMMARY
          
          HELPER_FUNCTIONS=$(grep -E "^func Record" metrics/metrics.go | wc -l)
          echo "Found $HELPER_FUNCTIONS helper functions" >> $GITHUB_STEP_SUMMARY
          
          if [ $HELPER_FUNCTIONS -ge 5 ]; then
            echo "✅ Good coverage of helper functions" >> $GITHUB_STEP_SUMMARY
          else
            echo "⚠️ Consider adding more helper functions" >> $GITHUB_STEP_SUMMARY
          fi

      - name: 🔍 Verify metrics documentation
        working-directory: ${{ env.HOMEPAGE_API_PATH }}
        run: |
          echo "### 📝 Metrics Documentation" >> $GITHUB_STEP_SUMMARY
          
          # Check if metrics have Help strings
          METRICS_WITH_HELP=$(grep -c "Help:" metrics/metrics.go || echo 0)
          TOTAL_METRICS=$(grep -c "promauto.New" metrics/metrics.go || echo 0)
          
          echo "Metrics with documentation: $METRICS_WITH_HELP/$TOTAL_METRICS" >> $GITHUB_STEP_SUMMARY
          
          if [ $METRICS_WITH_HELP -eq $TOTAL_METRICS ]; then
            echo "✅ All metrics are documented" >> $GITHUB_STEP_SUMMARY
          else
            echo "⚠️ Some metrics lack documentation" >> $GITHUB_STEP_SUMMARY
          fi

  # ============================================================================
  # 📋 Test Summary
  # ============================================================================
  metrics-test-summary:
    name: Metrics Test Summary
    runs-on: ubuntu-latest
    needs: 
      - metrics-package-tests
      - handler-instrumentation-tests
      - metrics-endpoint-tests
      - prometheus-alert-validation
      - metrics-benchmark
      - metrics-code-quality
    if: always()
    
    steps:
      - name: 📊 Generate summary
        run: |
          echo "# 📊 API Metrics Test Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Test Suite | Status |" >> $GITHUB_STEP_SUMMARY
          echo "|------------|--------|" >> $GITHUB_STEP_SUMMARY
          echo "| Metrics Package Tests | ${{ needs.metrics-package-tests.result == 'success' && '✅' || '❌' }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Handler Instrumentation | ${{ needs.handler-instrumentation-tests.result == 'success' && '✅' || '❌' }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Metrics Endpoint | ${{ needs.metrics-endpoint-tests.result == 'success' && '✅' || '❌' }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Alert Rules Validation | ${{ needs.prometheus-alert-validation.result == 'success' && '✅' || '❌' }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Performance Benchmark | ${{ needs.metrics-benchmark.result == 'success' && '✅' || '⚠️' }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Code Quality | ${{ needs.metrics-code-quality.result == 'success' && '✅' || '⚠️' }} |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [ "${{ needs.metrics-package-tests.result }}" == "success" ] && \
             [ "${{ needs.handler-instrumentation-tests.result }}" == "success" ] && \
             [ "${{ needs.metrics-endpoint-tests.result }}" == "success" ] && \
             [ "${{ needs.prometheus-alert-validation.result }}" == "success" ]; then
            echo "### ✅ All critical metrics tests passed!" >> $GITHUB_STEP_SUMMARY
          else
            echo "### ❌ Some metrics tests failed" >> $GITHUB_STEP_SUMMARY
          fi

      - name: ❌ Fail if critical tests failed
        if: |
          needs.metrics-package-tests.result != 'success' || 
          needs.handler-instrumentation-tests.result != 'success' || 
          needs.metrics-endpoint-tests.result != 'success' ||
          needs.prometheus-alert-validation.result != 'success'
        run: exit 1

