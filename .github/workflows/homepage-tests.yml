name: Homepage Integration Tests

on:
  push:
    branches: [ main, develop ]
    paths:
      - 'flux/clusters/homelab/infrastructure/homepage/**'
      - '.github/workflows/homepage-tests.yml'
  pull_request:
    branches: [ main, develop ]
    paths:
      - 'flux/clusters/homelab/infrastructure/homepage/**'
  workflow_dispatch:
  workflow_call:

env:
  GO_VERSION: '1.23.0'
  NODE_VERSION: '24'
  HOMEPAGE_PATH: 'flux/clusters/homelab/infrastructure/homepage'

jobs:
  # ============================================================================
  # Backend Tests (Go)
  # ============================================================================
  backend-tests:
    name: Backend Unit Tests
    runs-on: ubuntu-latest
    
    steps:
      - name: 📥 Checkout code
        uses: actions/checkout@v4

      - name: 🔧 Setup Go
        uses: actions/setup-go@v5
        with:
          go-version: ${{ env.GO_VERSION }}
          cache-dependency-path: ${{ env.HOMEPAGE_PATH }}/api/go.sum

      - name: 📦 Install dependencies
        working-directory: ${{ env.HOMEPAGE_PATH }}/api
        run: |
          go mod download
          go mod verify

      - name: 🧪 Run unit tests
        working-directory: ${{ env.HOMEPAGE_PATH }}/api
        run: |
          go test -v -race -coverprofile=coverage.out -covermode=atomic ./...

      - name: 📊 Generate coverage report
        working-directory: ${{ env.HOMEPAGE_PATH }}/api
        run: |
          go tool cover -func=coverage.out
          echo "### Test Coverage" >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          go tool cover -func=coverage.out >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY

      - name: 📈 Upload coverage to Codecov
        uses: codecov/codecov-action@v4
        with:
          files: ${{ env.HOMEPAGE_PATH }}/api/coverage.out
          flags: backend
          name: backend-coverage
          fail_ci_if_error: false

      - name: 🔍 Run go vet
        working-directory: ${{ env.HOMEPAGE_PATH }}/api
        run: go vet ./...

      - name: 🔍 Run staticcheck
        working-directory: ${{ env.HOMEPAGE_PATH }}/api
        run: |
          go install honnef.co/go/tools/cmd/staticcheck@latest
          staticcheck ./...

  # ============================================================================
  # Frontend Tests (TypeScript)
  # ============================================================================
  frontend-tests:
    name: Frontend Unit Tests
    runs-on: ubuntu-latest
    
    steps:
      - name: 📥 Checkout code
        uses: actions/checkout@v4

      - name: 🔧 Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          cache-dependency-path: ${{ env.HOMEPAGE_PATH }}/frontend/package-lock.json

      - name: 📦 Install dependencies
        working-directory: ${{ env.HOMEPAGE_PATH }}/frontend
        run: |
          echo "📦 Installing npm dependencies..."
          # Clear npm cache to avoid stale data
          npm cache clean --force
          
          # Try npm ci first, then fallback to npm install
          npm ci --legacy-peer-deps --no-audit --no-fund --prefer-offline || {
            echo "❌ npm ci failed, trying npm install..."
            # Remove node_modules and package-lock.json for clean install
            rm -rf node_modules package-lock.json
            npm install --legacy-peer-deps --no-audit --no-fund
          }
          
          # Verify jest-util is available
          echo "🔍 Verifying jest-util installation..."
          npm list jest-util || {
            echo "❌ jest-util not found, installing explicitly..."
            npm install jest-util@^29.7.0 --save-dev
          }

      - name: 🧪 Run unit tests
        working-directory: ${{ env.HOMEPAGE_PATH }}/frontend
        run: npm test -- --coverage --watchAll=false --passWithNoTests
        env:
          CI: true

      - name: 📊 Generate coverage report
        if: always()
        working-directory: ${{ env.HOMEPAGE_PATH }}/frontend
        run: |
          if [ -f coverage/lcov.info ]; then
            echo "### Frontend Test Coverage" >> $GITHUB_STEP_SUMMARY
            echo "Coverage report generated successfully" >> $GITHUB_STEP_SUMMARY
          fi

      - name: 📈 Upload coverage to Codecov
        uses: codecov/codecov-action@v4
        with:
          files: ${{ env.HOMEPAGE_PATH }}/frontend/coverage/lcov.info
          flags: frontend
          name: frontend-coverage
          fail_ci_if_error: false

      - name: 🔍 Run TypeScript check
        working-directory: ${{ env.HOMEPAGE_PATH }}/frontend
        run: npm run build

      - name: 🔍 Run ESLint
        working-directory: ${{ env.HOMEPAGE_PATH }}/frontend
        run: npm run lint || true
        continue-on-error: true

  # ============================================================================
  # Build Verification
  # ============================================================================
  build-verification:
    name: Build Verification
    runs-on: ubuntu-latest
    needs: [backend-tests, frontend-tests]
    
    steps:
      - name: 📥 Checkout code
        uses: actions/checkout@v4

      - name: 🔧 Setup Go
        uses: actions/setup-go@v5
        with:
          go-version: ${{ env.GO_VERSION }}
          cache-dependency-path: ${{ env.HOMEPAGE_PATH }}/api/go.sum

      - name: 🔧 Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: 🏗️ Build backend
        working-directory: ${{ env.HOMEPAGE_PATH }}/api
        run: |
          go mod download
          go build -v -o bruno-site-api .

      - name: 🏗️ Build frontend
        working-directory: ${{ env.HOMEPAGE_PATH }}/frontend
        run: |
          echo "📦 Installing dependencies for build..."
          npm cache clean --force
          npm ci --legacy-peer-deps --no-audit --no-fund --prefer-offline || {
            echo "❌ npm ci failed, trying npm install..."
            rm -rf node_modules package-lock.json
            npm install --legacy-peer-deps --no-audit --no-fund
          }
          
          echo "🏗️ Building frontend..."
          npm run build

      - name: ✅ Verify builds
        run: |
          echo "### Build Verification" >> $GITHUB_STEP_SUMMARY
          echo "✅ Backend binary created" >> $GITHUB_STEP_SUMMARY
          echo "✅ Frontend assets built" >> $GITHUB_STEP_SUMMARY
          ls -lh ${{ env.HOMEPAGE_PATH }}/api/bruno-site-api
          ls -lh ${{ env.HOMEPAGE_PATH }}/frontend/dist/

  # ============================================================================
  # Metrics Tests
  # ============================================================================
  metrics-tests:
    name: Metrics Tests
    runs-on: ubuntu-latest
    
    steps:
      - name: 📥 Checkout code
        uses: actions/checkout@v4

      - name: 🔧 Setup Go
        uses: actions/setup-go@v5
        with:
          go-version: ${{ env.GO_VERSION }}
          cache-dependency-path: ${{ env.HOMEPAGE_PATH }}/api/go.sum

      - name: 📦 Install dependencies
        working-directory: ${{ env.HOMEPAGE_PATH }}/api
        run: |
          go mod download
          go mod verify

      - name: 🧪 Run metrics package tests
        working-directory: ${{ env.HOMEPAGE_PATH }}/api
        run: |
          echo "### 📊 Metrics Package Tests" >> $GITHUB_STEP_SUMMARY
          go test -v -race -coverprofile=metrics-coverage.out ./metrics/
          
          if [ $? -eq 0 ]; then
            echo "✅ All metrics tests passed" >> $GITHUB_STEP_SUMMARY
          else
            echo "❌ Metrics tests failed" >> $GITHUB_STEP_SUMMARY
            exit 1
          fi

      - name: 📊 Metrics package coverage
        working-directory: ${{ env.HOMEPAGE_PATH }}/api
        run: |
          COVERAGE=$(go tool cover -func=metrics-coverage.out | grep total | awk '{print $3}')
          echo "### Metrics Package Coverage: $COVERAGE" >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          go tool cover -func=metrics-coverage.out >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY

      - name: 🧪 Run handler metrics tests
        working-directory: ${{ env.HOMEPAGE_PATH }}/api
        run: |
          echo "### 🎯 Handler Metrics Tests" >> $GITHUB_STEP_SUMMARY
          go test -v -race -coverprofile=handlers-coverage.out ./handlers/
          
          COVERAGE=$(go tool cover -func=handlers-coverage.out | grep total | awk '{print $3}')
          echo "Handler Coverage: $COVERAGE" >> $GITHUB_STEP_SUMMARY

      - name: 🔍 Verify /metrics endpoint
        working-directory: ${{ env.HOMEPAGE_PATH }}/api
        run: |
          echo "### 📈 Metrics Endpoint Verification" >> $GITHUB_STEP_SUMMARY
          
          # Check if metrics endpoint is registered in router
          if grep -q "r.GET.*\"/metrics\"" router/router.go; then
            echo "✅ Metrics endpoint found in router" >> $GITHUB_STEP_SUMMARY
          else
            echo "❌ Metrics endpoint not found in router" >> $GITHUB_STEP_SUMMARY
            exit 1
          fi

  # ============================================================================
  # Integration Tests (requires services)
  # ============================================================================
  integration-tests:
    name: Integration Tests
    runs-on: ubuntu-latest
    needs: [backend-tests, frontend-tests]
    # Only run on main branch or manual dispatch, and skip for PRs
    # Note: Integration tests require the agent-sre image to be published first
    if: (github.event_name == 'workflow_dispatch' || github.ref == 'refs/heads/main') && github.event_name != 'pull_request'
    continue-on-error: true

    steps:
      - name: 📥 Checkout code
        uses: actions/checkout@v4

      - name: 📋 Integration test status
        run: |
          echo "### Integration Test Results" >> $GITHUB_STEP_SUMMARY
          echo "⚠️ Integration tests skipped - requires agent-sre image" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "To enable integration tests:" >> $GITHUB_STEP_SUMMARY
          echo "1. Build and push agent-sre image to ghcr.io/brunovlucena/agent-sre:latest" >> $GITHUB_STEP_SUMMARY
          echo "2. Re-enable the services section in this workflow" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "_Note: Unit and build tests are still comprehensive_" >> $GITHUB_STEP_SUMMARY

  # ============================================================================
  # Test Summary
  # ============================================================================
  test-summary:
    name: Test Summary
    runs-on: ubuntu-latest
    needs: [backend-tests, frontend-tests, build-verification, metrics-tests]
    if: always()
    
    steps:
      - name: 📊 Generate summary
        run: |
          echo "# 🧪 Homepage Integration Test Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Test Suite | Status |" >> $GITHUB_STEP_SUMMARY
          echo "|------------|--------|" >> $GITHUB_STEP_SUMMARY
          echo "| Backend Tests | ${{ needs.backend-tests.result == 'success' && '✅' || '❌' }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Frontend Tests | ${{ needs.frontend-tests.result == 'success' && '✅' || '❌' }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Metrics Tests | ${{ needs.metrics-tests.result == 'success' && '✅' || '❌' }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Build Verification | ${{ needs.build-verification.result == 'success' && '✅' || '❌' }} |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [ "${{ needs.backend-tests.result }}" == "success" ] && \
             [ "${{ needs.frontend-tests.result }}" == "success" ] && \
             [ "${{ needs.metrics-tests.result }}" == "success" ] && \
             [ "${{ needs.build-verification.result }}" == "success" ]; then
            echo "### ✅ All tests passed!" >> $GITHUB_STEP_SUMMARY
          else
            echo "### ❌ Some tests failed" >> $GITHUB_STEP_SUMMARY
          fi

      - name: ❌ Fail if tests failed
        if: needs.backend-tests.result != 'success' || needs.frontend-tests.result != 'success' || needs.metrics-tests.result != 'success' || needs.build-verification.result != 'success'
        run: exit 1

